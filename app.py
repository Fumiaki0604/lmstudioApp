import json
import time
from datetime import datetime
from pathlib import Path

import requests
import trafilatura
import streamlit as st

# =============================
# Constants
# =============================
DEFAULT_UA = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/123.0 Safari/537.36"
)

DEFAULT_BUDDY_PROMPT = """ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€ŒåŠ©æ‰‹å…¼ç›¸æ£’ã€ã§ã™ã€‚
å£èª¿: ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§è»½å¿«ã€‚ãŸã ã—é¦´ã‚Œé¦´ã‚Œã—ã™ããšã€æ•¬èªã¨ã‚¿ãƒ¡å£ã®ä¸­é–“ã€‚
æ–¹é‡:
- çµè«–â†’ç†ç”±â†’æ¬¡ã®ä¸€æ‰‹ã€ã®é †ã§è©±ã™ã€‚
- äº‹å®Ÿã¨æ¨æ¸¬ã‚’åˆ†ã‘ã€æ›–æ˜§ãªç‚¹ã¯æ­£ç›´ã«ã€Œä¸ç¢ºã‹ã€ã¨è¨€ã†ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒâ€œæ¬¡ã«å‹•ã‘ã‚‹â€å½¢ã§è¿”ã™ã€‚
- ç„¡é§„ã«é•·ãã—ãªã„ã€‚èª­ã¿ã‚„ã™ãã€å®Ÿå‹™å‘ãã«ã€‚
"""

SUMMARY_ADDON = """è¿½åŠ ãƒ«ãƒ¼ãƒ«ï¼ˆURLè¦ç´„ï¼‰:
- é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãï¼ˆ5ã€œ10ï¼‰
- æ•°å€¤ãƒ»å›ºæœ‰åè©ãƒ»çµè«–ã¯è½ã¨ã•ãªã„
- æœ€å¾Œã«ã€Œæ„æ€æ±ºå®šã®æ³¨æ„ç‚¹ã€ã‚’1ã€œ3å€‹
"""

STORE_DIR = Path.home() / ".lmstudio_assistant"
PROMPTS_FILE = STORE_DIR / "prompts.json"


# =============================
# Persistence
# =============================
def _default_store():
    return {
        "active": "default",
        "prompts": {
            "default": DEFAULT_BUDDY_PROMPT,
        },
    }


def load_store() -> dict:
    try:
        if PROMPTS_FILE.exists():
            data = json.loads(PROMPTS_FILE.read_text(encoding="utf-8"))
            if "prompts" not in data or not isinstance(data["prompts"], dict):
                return _default_store()
            if "active" not in data or data["active"] not in data["prompts"]:
                data["active"] = next(iter(data["prompts"].keys()), "default")
            return data
    except Exception:
        pass
    return _default_store()


def save_store(store: dict) -> None:
    STORE_DIR.mkdir(parents=True, exist_ok=True)
    PROMPTS_FILE.write_text(json.dumps(store, ensure_ascii=False, indent=2), encoding="utf-8")


def current_buddy_prompt() -> str:
    store = st.session_state["prompt_store"]
    active = store.get("active", "default")
    prompts = store.get("prompts", {})
    return (prompts.get(active) or DEFAULT_BUDDY_PROMPT).strip()


# =============================
# LM Studio helpers
# =============================
def lmstudio_models(base_url: str, timeout: int = 3):
    r = requests.get(base_url.rstrip("/") + "/models", timeout=timeout)
    r.raise_for_status()
    return [m["id"] for m in r.json().get("data", [])]


def call_lmstudio_chat_messages(
    base_url: str,
    model: str,
    messages: list,
    temperature: float,
    max_tokens: int,
    timeout: int,
):
    endpoint = base_url.rstrip("/") + "/chat/completions"
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "stream": False,
    }
    r = requests.post(endpoint, json=payload, timeout=timeout)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]


# =============================
# Web text extraction
# =============================
def fetch_html(url: str, timeout: int = 20) -> str:
    r = requests.get(url, timeout=timeout, headers={"User-Agent": DEFAULT_UA})
    r.raise_for_status()
    return r.text


def extract_main_text(html: str) -> str:
    text = trafilatura.extract(
        html,
        output_format="txt",
        include_comments=False,
        include_tables=True,
        favor_precision=True,
    )
    return (text or "").strip()


def build_summary_prompt(url: str, text: str, max_chars: int) -> str:
    if len(text) <= max_chars:
        clipped = text
    else:
        head = text[: int(max_chars * 0.7)]
        tail = text[-int(max_chars * 0.3):]
        clipped = head + "\n\n...(ä¸­ç•¥)...\n\n" + tail

    return f"""æ¬¡ã®Webãƒšãƒ¼ã‚¸æœ¬æ–‡ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚

URL: {url}

æœ¬æ–‡:
\"\"\"\n{clipped}\n\"\"\"
"""


# =============================
# UI helpers
# =============================
def label_max_chars(n: int) -> str:
    if n <= 3000:
        return "âš¡ é€Ÿã„ï¼ˆè¦ç‚¹ä¸­å¿ƒï¼‰"
    if n <= 6000:
        return "âš–ï¸ ãƒãƒ©ãƒ³ã‚¹è‰¯ã—"
    return "ğŸ§  é«˜ç²¾åº¦ï¼ˆã‚„ã‚„é…ã„ï¼‰"


def label_max_tokens(n: int) -> str:
    if n <= 500:
        return "ğŸ§¾ çŸ­ã‚"
    if n <= 900:
        return "ğŸ“ æ¨™æº–"
    return "ğŸ“š ã—ã£ã‹ã‚Š"


def normalize_model_output(text: str) -> str:
    if not text:
        return text
    return (
        text.replace("<br/>", "\n")
        .replace("<br>", "\n")
        .replace("&nbsp;", " ")
    )


# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="ç›¸æ£’LLMï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰", layout="centered")
st.title("ç›¸æ£’LLMï¼ˆãƒ­ãƒ¼ã‚«ãƒ« / LM Studioï¼‰")

# ---- session state ----
if "chat_messages" not in st.session_state:
    st.session_state["chat_messages"] = []
if "url" not in st.session_state:
    st.session_state["url"] = ""
if "last_user_prompt" not in st.session_state:
    st.session_state["last_user_prompt"] = ""
if "prompt_store" not in st.session_state:
    st.session_state["prompt_store"] = load_store()

# ---- sidebar ----
with st.sidebar:
    st.header("æ¥ç¶šè¨­å®š")
    base_url = st.text_input("LM Studio Base URL", "http://localhost:1234/v1")
    if st.button("ğŸ”„ æ¥ç¶šã‚’å†ç¢ºèª"):
        st.rerun()

    models, lm_ok, err = [], False, None
    t0 = time.time()
    try:
        models = lmstudio_models(base_url)
        lm_ok = True
    except Exception as e:
        err = e
    elapsed = int((time.time() - t0) * 1000)
    checked_at = datetime.now().strftime("%H:%M:%S")

    if lm_ok:
        st.success(f"ğŸŸ¢ æ¥ç¶šä¸­ï¼ˆ{checked_at} / {elapsed}msï¼‰")
    else:
        st.error("ğŸ”´ æœªæ¥ç¶š")
        st.caption(err)

    st.divider()
    st.header("ç”Ÿæˆè¨­å®š")
    max_chars = st.slider("å…¥åŠ›æ–‡å­—æ•°ï¼ˆè¦ç´„ï¼‰", 2000, 12000, 4000, 500)
    st.caption(label_max_chars(max_chars))

    max_tokens = st.slider("å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³", 200, 2000, 800, 50)
    st.caption(label_max_tokens(max_tokens))

    temperature = st.slider("Temperature", 0.0, 1.5, 0.3, 0.1)

    st.divider()
    st.header("ç›¸æ£’è¨­å®šï¼ˆè¡¨ç¤ºã®ã¿ï¼‰")
    store = st.session_state["prompt_store"]
    active_name = store.get("active", "default")
    st.caption(f"ç¾åœ¨ã®ç›¸æ£’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: **{active_name}**")
    st.caption("â€»ç·¨é›†ã¯âš™ï¸è¨­å®šã‚¿ãƒ–ã§è¡Œã„ã¾ã™ï¼ˆã“ã“ã«ã¯è¡¨ç¤ºã—ã¾ã›ã‚“ï¼‰ã€‚")

if not lm_ok:
    st.stop()

model = st.selectbox("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«", models)

tab_chat, tab_summary, tab_settings = st.tabs(["ğŸ’¬ Chatï¼ˆç›¸æ£’ï¼‰", "ğŸ“„ URLè¦ç´„", "âš™ï¸ è¨­å®š"])

# =============================
# Chat tab (LINEé¢¨ï¼šå…¥åŠ›æ¬„1ã¤ + ä¸‹å›ºå®š)
# =============================
with tab_chat:
    st.caption("é›‘è«‡ãƒ»ç›¸è«‡ãƒ»æ€è€ƒæ•´ç†ã€‚æ™®é€šã«è©±ã—ã‹ã‘ã¦OKã€‚")

    st.markdown(
        """
        <style>
        .dock {
            position: fixed;
            left: 0;
            right: 0;
            bottom: 0;
            padding: 0.75rem 1rem;
            background: rgba(15, 16, 18, 0.92);
            backdrop-filter: blur(8px);
            border-top: 1px solid rgba(255,255,255,0.08);
            z-index: 1000;
        }
        .spacer { height: 110px; }
        footer {visibility: hidden;}
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ä¼šè©±ãƒ­ã‚°
    for msg in st.session_state["chat_messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # å…¥åŠ›ãƒãƒ¼ã«è¢«ã‚‰ãªã„ãŸã‚ã®ã‚¹ãƒšãƒ¼ã‚µãƒ¼
    st.markdown('<div class="spacer"></div>', unsafe_allow_html=True)

    # ä¸‹å›ºå®šå…¥åŠ›ãƒãƒ¼ï¼ˆ1ã¤ï¼‰
    st.markdown('<div class="dock">', unsafe_allow_html=True)
    with st.form("dock_form", clear_on_submit=True):
        col1, col2 = st.columns([8, 1])
        with col1:
            user_prompt = st.text_input(
                "message",
                placeholder="ç›¸æ£’ã«è©±ã—ã‹ã‘ã‚‹â€¦",
                label_visibility="collapsed",
            )
        with col2:
            submitted = st.form_submit_button("â–¶ï¸")
    st.markdown("</div>", unsafe_allow_html=True)

    if submitted and user_prompt.strip():
        user_prompt = user_prompt.strip()
        st.session_state["last_user_prompt"] = user_prompt

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã‚’å±¥æ­´ã¸
        st.session_state["chat_messages"].append({"role": "user", "content": user_prompt})

        system = current_buddy_prompt()
        history = st.session_state["chat_messages"][-12:]
        messages = [{"role": "system", "content": system}] + history

        with st.spinner("è€ƒãˆä¸­â€¦"):
            try:
                reply = call_lmstudio_chat_messages(
                    base_url=base_url,
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    timeout=180,
                )
                reply = normalize_model_output(reply)
            except Exception as e:
                reply = f"ã”ã‚ã‚“ã€ä»Šã¡ã‚‡ã„å¤±æ•—ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}"

        st.session_state["chat_messages"].append({"role": "assistant", "content": reply})

        # é€ä¿¡å¾Œã¯å†æç”»ã—ã¦æœ€æ–°ãƒ­ã‚°ã‚’è¡¨ç¤º
        st.rerun()

    if st.button("ğŸ§¹ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state["chat_messages"] = []
        st.session_state["last_user_prompt"] = ""
        st.rerun()

# =============================
# URL Summary tab
# =============================
with tab_summary:
    url = st.text_input("è¦ç´„ã—ãŸã„URL", key="url", placeholder="https://...")

    if st.button("è¦ç´„ã™ã‚‹", type="primary"):
        if not url.strip():
            st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            st.stop()

        with st.spinner("å–å¾—ãƒ»è¦ç´„ä¸­â€¦"):
            html = fetch_html(url)
            text = extract_main_text(html)
            prompt = build_summary_prompt(url, text, max_chars)

            system = (current_buddy_prompt() + "\n\n" + SUMMARY_ADDON).strip()
            messages = [
                {"role": "system", "content": system},
                {"role": "user", "content": prompt},
            ]

            summary = call_lmstudio_chat_messages(
                base_url=base_url,
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                timeout=180,
            )
            summary = normalize_model_output(summary)

        st.subheader("è¦ç´„çµæœ")
        st.markdown(summary)

        with st.expander("æŠ½å‡ºã—ãŸæœ¬æ–‡ï¼ˆå…ˆé ­ï¼‰ã‚’è¦‹ã‚‹"):
            st.text(text[:2000])

# =============================
# Settings tab (Prompt editor + persistence)
# =============================
with tab_settings:
    st.subheader("ç›¸æ£’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä¿å­˜ãƒ»åˆ‡æ›¿ï¼‰")
    st.caption("ã“ã“ã§ã ã‘ç·¨é›†ã§ãã¾ã™ã€‚Chat/URLè¦ç´„ç”»é¢ã«ã¯è¡¨ç¤ºã—ã¾ã›ã‚“ã€‚")

    store = st.session_state["prompt_store"]
    prompts = store.get("prompts", {})
    if not prompts:
        store = _default_store()
        prompts = store["prompts"]
        st.session_state["prompt_store"] = store
        save_store(store)

    names = sorted(prompts.keys())
    active = store.get("active", names[0])

    col1, col2 = st.columns([2, 1])
    with col1:
        selected = st.selectbox("ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ", options=names, index=names.index(active) if active in names else 0)
    with col2:
        if st.button("âœ… ã“ã®ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä½¿ã†"):
            store["active"] = selected
            st.session_state["prompt_store"] = store
            save_store(store)
            st.success(f"é©ç”¨ã—ã¾ã—ãŸ: {selected}")

    edit_key = f"prompt_edit_{selected}"
    if edit_key not in st.session_state:
        st.session_state[edit_key] = prompts.get(selected, "").strip()

    edited = st.text_area(
        "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ¬æ–‡ï¼ˆã“ã“ã§ç·¨é›†ï¼‰",
        value=st.session_state[edit_key],
        height=260,
    )

    cA, cB, cC = st.columns([1, 1, 2])
    with cA:
        if st.button("ğŸ’¾ ä¸Šæ›¸ãä¿å­˜"):
            prompts[selected] = edited.strip()
            store["prompts"] = prompts
            st.session_state["prompt_store"] = store
            save_store(store)
            st.success("ä¿å­˜ã—ã¾ã—ãŸã€‚")

    with cB:
        if st.button("â†©ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã™"):
            prompts[selected] = DEFAULT_BUDDY_PROMPT
            store["prompts"] = prompts
            st.session_state["prompt_store"] = store
            save_store(store)
            st.session_state[edit_key] = DEFAULT_BUDDY_PROMPT
            st.success("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚")

    with cC:
        st.caption(f"ä¿å­˜å…ˆ: `{PROMPTS_FILE}`")

    st.divider()
    st.subheader("ãƒ—ãƒªã‚»ãƒƒãƒˆç®¡ç†")

    colN1, colN2, colN3 = st.columns([2, 1, 1])
    with colN1:
        new_name = st.text_input("æ–°ã—ã„ãƒ—ãƒªã‚»ãƒƒãƒˆå", placeholder="ä¾‹: buddy_casual / buddy_strict")
    with colN2:
        if st.button("â• æ–°è¦ä½œæˆ"):
            nn = (new_name or "").strip()
            if not nn:
                st.warning("ãƒ—ãƒªã‚»ãƒƒãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            elif nn in prompts:
                st.warning("åŒåã®ãƒ—ãƒªã‚»ãƒƒãƒˆãŒæ—¢ã«ã‚ã‚Šã¾ã™ã€‚")
            else:
                prompts[nn] = DEFAULT_BUDDY_PROMPT
                store["prompts"] = prompts
                store["active"] = nn
                st.session_state["prompt_store"] = store
                save_store(store)
                st.success(f"ä½œæˆã—ã¦é©ç”¨ã—ã¾ã—ãŸ: {nn}")
                st.rerun()
    with colN3:
        if st.button("ğŸ—‘ é¸æŠãƒ—ãƒªã‚»ãƒƒãƒˆå‰Šé™¤"):
            if selected == "default":
                st.warning("default ã¯å‰Šé™¤ã§ãã¾ã›ã‚“ã€‚")
            else:
                prompts.pop(selected, None)
                store["prompts"] = prompts
                if store.get("active") == selected:
                    store["active"] = "default" if "default" in prompts else next(iter(prompts.keys()))
                st.session_state["prompt_store"] = store
                save_store(store)
                st.success(f"å‰Šé™¤ã—ã¾ã—ãŸ: {selected}")
                st.rerun()